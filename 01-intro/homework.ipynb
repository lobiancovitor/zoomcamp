{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(filename: str):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df[\"lpep_pickup_datetime\"] = pd.to_datetime(df[\"lpep_pickup_datetime\"])\n",
    "    df[\"lpep_dropoff_datetime\"] = pd.to_datetime(df[\"lpep_dropoff_datetime\"])\n",
    "\n",
    "    df[\"duration\"] = df[\"lpep_dropoff_datetime\"] - df[\"lpep_pickup_datetime\"] # our target\n",
    "\n",
    "    td = df[\"duration\"].iloc[0]\n",
    "    df[\"duration\"] = df[\"duration\"].apply(lambda td: td.total_seconds() / 60) # turn it into minutes\n",
    "    \n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)] # remove outliers / errors\n",
    "\n",
    "    # features we are going to use\n",
    "    categorical = [\"PULocationID\", \"DOLocationID\"]\n",
    "    numerical = [\"trip_distance\"]\n",
    "\n",
    "    df[categorical] = df[categorical].astype(str) # ints that will be used as categorial features\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_df(\"../data/green_tripdata_2021-01.parquet\") # train the model on january\n",
    "df_val = read_df(\"../data/green_tripdata_2021-02.parquet\")   # validate the model on febuary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.56"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df_train['duration'].std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a better feature on existing columns = better model (reduce mse)\n",
    "df_train[\"PU_DO\"] = df_train[\"PULocationID\"] + '_' + df_train[\"DOLocationID\"]\n",
    "df_val[\"PU_DO\"] = df_val[\"PULocationID\"] + '_' + df_val[\"DOLocationID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dicts into feature matrices\n",
    "dv = DictVectorizer() # performs auto one-hot encoding on categorial features\n",
    "\n",
    "categorical = [\"PU_DO\", \"PULocationID\", \"DOLocationID\"]\n",
    "numerical = [\"trip_distance\"]\n",
    "\n",
    "train_dict = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "X_train = dv.fit_transform(train_dict) # convert dict to matrix\n",
    "\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient=\"records\")\n",
    "X_val = dv.transform(val_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our target on train and validation sets\n",
    "target = \"duration\"\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.397725977550327"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by saving both objects, dv can apply the transformations to future datasets \n",
    "# and lr can make the predictions after that\n",
    "\n",
    "with open(\"../models/lin_reg.bin\", \"wb\") as f_out:\n",
    "    pickle.dump((dv, lr), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook problems (main problems: reproducibility and automation)\n",
    "\n",
    "- Hard to keep track of experiments    -> Experiment Tracking (MLFlow)\n",
    "- Track model versions and its metrics -> Model Registry (MLFlow)\n",
    "- Code execution order                 -> Pipelines (steps: load - vectorize - train...)\n",
    "- Deployment (serve the pickle to users)\n",
    "- Monitoring (drops in performance -> alerts and automatic retraining -> serve new model)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
