{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/zoomcamp/02-experiment-tracking/mlruns/1', creation_time=1734313537028, experiment_id='1', last_update_time=1734313537028, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking URI: sqlite:///mlflow.db\n"
     ]
    }
   ],
   "source": [
    "print(\"Tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(filename: str):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df[\"lpep_pickup_datetime\"] = pd.to_datetime(df[\"lpep_pickup_datetime\"])\n",
    "    df[\"lpep_dropoff_datetime\"] = pd.to_datetime(df[\"lpep_dropoff_datetime\"])\n",
    "\n",
    "    df[\"duration\"] = df[\"lpep_dropoff_datetime\"] - df[\"lpep_pickup_datetime\"] # our target\n",
    "\n",
    "    td = df[\"duration\"].iloc[0]\n",
    "    df[\"duration\"] = df[\"duration\"].apply(lambda td: td.total_seconds() / 60) # turn it into minutes\n",
    "    \n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)] # remove outliers / errors\n",
    "\n",
    "    # features we are going to use\n",
    "    categorical = [\"PULocationID\", \"DOLocationID\"]\n",
    "    numerical = [\"trip_distance\"]\n",
    "\n",
    "    df[categorical] = df[categorical].astype(str) # ints that will be used as categorial features\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_df(\"../data/green_tripdata_2021-01.parquet\") # train the model on january\n",
    "df_val = read_df(\"../data/green_tripdata_2021-02.parquet\")   # validate the model on febuary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(11.56)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df_train['duration'].std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a better feature on existing columns = better model (reduce mse)\n",
    "df_train[\"PU_DO\"] = df_train[\"PULocationID\"] + '_' + df_train[\"DOLocationID\"]\n",
    "df_val[\"PU_DO\"] = df_val[\"PULocationID\"] + '_' + df_val[\"DOLocationID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dicts into feature matrices\n",
    "dv = DictVectorizer() # performs auto one-hot encoding on categorial features\n",
    "\n",
    "categorical = [\"PU_DO\", \"PULocationID\", \"DOLocationID\"]\n",
    "numerical = [\"trip_distance\"]\n",
    "\n",
    "train_dict = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "X_train = dv.fit_transform(train_dict) # convert dict to matrix\n",
    "\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient=\"records\")\n",
    "X_val = dv.transform(val_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our target on train and validation sets\n",
    "target = \"duration\"\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/workspaces'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_val, y_pred)\n\u001b[1;32m     15\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, rmse)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/lin_reg.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlartifacts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# log the model from a local path\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/zoomcamp/.venv/lib/python3.13/site-packages/mlflow/tracking/fluent.py:1179\u001b[0m, in \u001b[0;36mlog_artifact\u001b[0;34m(local_path, artifact_path, run_id)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;124;03mLog a local file or directory as an artifact of the currently active run. If no run is\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;124;03mactive, this method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;124;03m            mlflow.log_artifact(path)\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m-> 1179\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/zoomcamp/.venv/lib/python3.13/site-packages/mlflow/tracking/client.py:1933\u001b[0m, in \u001b[0;36mMlflowClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m   1929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id\u001b[38;5;241m.\u001b[39mstartswith(TRACE_REQUEST_ID_PREFIX):\n\u001b[1;32m   1930\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m   1931\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid run id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. `log_artifact` run id must map to a valid run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1932\u001b[0m     )\n\u001b[0;32m-> 1933\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/zoomcamp/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/client.py:842\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m    840\u001b[0m     artifact_repo\u001b[38;5;241m.\u001b[39mlog_artifacts(local_path, path_name)\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 842\u001b[0m     \u001b[43martifact_repo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/zoomcamp/.venv/lib/python3.13/site-packages/mlflow/store/artifact/local_artifact_repo.py:43\u001b[0m, in \u001b[0;36mLocalArtifactRepository.log_artifact\u001b[0;34m(self, local_file, artifact_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m artifact_dir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     40\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir, artifact_path) \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(artifact_dir):\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopy2(local_file, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(artifact_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(local_file)))\n",
      "File \u001b[0;32m~/Documents/GitHub/zoomcamp/.venv/lib/python3.13/site-packages/mlflow/utils/file_utils.py:211\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m errno\u001b[38;5;241m.\u001b[39mEEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(target):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m~/Documents/GitHub/zoomcamp/.venv/lib/python3.13/site-packages/mlflow/utils/file_utils.py:208\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    206\u001b[0m target \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, name) \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m root\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m errno\u001b[38;5;241m.\u001b[39mEEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(target):\n",
      "File \u001b[0;32m<frozen os>:217\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:217\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "    \u001b[0;31m[... skipping similar frames: makedirs at line 217 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:217\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:227\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/workspaces'"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(): # everything inside is associated with the current run\n",
    "    \n",
    "    mlflow.set_tag(\"developer\", \"vitor\")\n",
    "    \n",
    "    mlflow.log_param(\"train-data-path\", \"../data/green_tripdata_2021-01.parquet\")\n",
    "    mlflow.log_param(\"valid-data-path\", \"../data/green_tripdata_2021-02.parquet\")\n",
    "    \n",
    "    alpha = 0.1\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    lr = Lasso(alpha)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    mlflow.log_artifact(local_path=\"models/lin_reg.bin\", artifact_path=\"mlartifacts\") # log the model from a local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/vitor/Documents/GitHub/zoomcamp/02-experiment-tracking\n",
      "Does /workspaces exist?: False\n",
      "Are we in a container?: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Check if /workspaces exists\n",
    "print(\"Does /workspaces exist?:\", os.path.exists(\"/workspaces\"))\n",
    "\n",
    "# Check if we're in a container (one way to check)\n",
    "print(\"Are we in a container?:\", os.path.exists(\"/.dockerenv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by saving both objects, dv can apply the transformations to future datasets \n",
    "# and lr can make the predictions after that\n",
    "\n",
    "with open(\"../models/lin_reg.bin\", \"wb\") as f_out:\n",
    "    pickle.dump((dv, lr), f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will be a run for each set of parameters, associated with the experiment\n",
    "# With this, we can compare the results of different runs based on metrics\n",
    "\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params) # log params to mlflow\n",
    "        booster = xgb.train(\n",
    "            params=params, # also pass the params to the model\n",
    "            dtrain=train,  # on the training data\n",
    "            num_boost_round=1000, # 1000 iterations of the booster\n",
    "            evals=[(valid, \"validation\")], # validation set to control the optimization (minimize error on validation set)\n",
    "            early_stopping_rounds=50 # stop if the error on the validation set does not improve for 50 rounds\n",
    "        )\n",
    "        y_pred = booster.predict(valid) # make predictions on the validation set, get the target\n",
    "        rmse = mean_squared_error(y_val, y_pred) # hyperopt minimizes the error\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        \n",
    "    return {\"loss\": rmse, \"status\": STATUS_OK}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the range in which hyperopt will search for the best parameters\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0), # exp(-3), exp(0)\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "# pass the information to the fmin method (will minimize the output of the objective function)\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_rate\": 0.06739331004838427,\n",
    "    \"max_depth\": 25,\n",
    "    \"min_child_weight\": 1.519461591196802,\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"reg_alpha\": 0.02979646034040559,\n",
    "    \"reg_lambda\": 0.21172810212072343,\n",
    "    \"seed\": 42,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog() # log all the parameters and metrics of the model\n",
    "\n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=train,\n",
    "    num_boost_round=10,\n",
    "    evals=[(valid, \"validation\")],\n",
    "    early_stopping_rounds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Management\n",
    "\n",
    "- Model Versioning "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
