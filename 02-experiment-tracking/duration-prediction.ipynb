{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/zoomcamp/02-experiment-tracking/mlruns/1', creation_time=1734313537028, experiment_id='1', last_update_time=1734313537028, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(experiment_name=\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking URI: sqlite:///mlflow.db\n"
     ]
    }
   ],
   "source": [
    "print(\"Tracking URI:\", mlflow.get_tracking_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(filename: str):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df[\"lpep_pickup_datetime\"] = pd.to_datetime(df[\"lpep_pickup_datetime\"])\n",
    "    df[\"lpep_dropoff_datetime\"] = pd.to_datetime(df[\"lpep_dropoff_datetime\"])\n",
    "\n",
    "    df[\"duration\"] = df[\"lpep_dropoff_datetime\"] - df[\"lpep_pickup_datetime\"] # our target\n",
    "\n",
    "    td = df[\"duration\"].iloc[0]\n",
    "    df[\"duration\"] = df[\"duration\"].apply(lambda td: td.total_seconds() / 60) # turn it into minutes\n",
    "    \n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)] # remove outliers / errors\n",
    "\n",
    "    # features we are going to use\n",
    "    categorical = [\"PULocationID\", \"DOLocationID\"]\n",
    "    numerical = [\"trip_distance\"]\n",
    "\n",
    "    df[categorical] = df[categorical].astype(str) # ints that will be used as categorial features\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_df(\"../data/green_tripdata_2021-01.parquet\") # train the model on january\n",
    "df_val = read_df(\"../data/green_tripdata_2021-02.parquet\")   # validate the model on febuary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.56"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df_train['duration'].std(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a better feature on existing columns = better model (reduce mse)\n",
    "df_train[\"PU_DO\"] = df_train[\"PULocationID\"] + '_' + df_train[\"DOLocationID\"]\n",
    "df_val[\"PU_DO\"] = df_val[\"PULocationID\"] + '_' + df_val[\"DOLocationID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dicts into feature matrices\n",
    "dv = DictVectorizer() # performs auto one-hot encoding on categorial features\n",
    "\n",
    "categorical = [\"PU_DO\", \"PULocationID\", \"DOLocationID\"]\n",
    "numerical = [\"trip_distance\"]\n",
    "\n",
    "train_dict = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "X_train = dv.fit_transform(train_dict) # convert dict to matrix\n",
    "\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient=\"records\")\n",
    "X_val = dv.transform(val_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our target on train and validation sets\n",
    "target = \"duration\"\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: c8e1bac08f5e4e6f89b525673969161d\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(): # everything inside is associated with the current run\n",
    "    \n",
    "    mlflow.set_tag(\"developer\", \"vitor\")\n",
    "    \n",
    "    mlflow.log_param(\"train-data-path\", \"../data/green_tripdata_2021-01.parquet\")\n",
    "    mlflow.log_param(\"valid-data-path\", \"../data/green_tripdata_2021-02.parquet\")\n",
    "    \n",
    "    alpha = 0.01\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    lr = Lasso(alpha)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by saving both objects, dv can apply the transformations to future datasets \n",
    "# and lr can make the predictions after that\n",
    "\n",
    "with open(\"../models/lin_reg.bin\", \"wb\") as f_out:\n",
    "    pickle.dump((dv, lr), f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
